# üìù Chatbot d'Orientation Scolaire avec NLTK et Transformers

# üìå 1. Importation des biblioth√®ques
import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from transformers import pipeline
import pickle
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# T√©l√©charger les ressources NLTK n√©cessaires
nltk.download('punkt')
nltk.download('stopwords')

# üìå 2. Chargement du dataset
# Vous devez ajuster le chemin du dataset en fonction de votre structure de r√©pertoires.
df = pd.read_csv("./data/dataset_orientation_scolaire.csv")

# Afficher les premi√®res lignes du dataset
print(df.head())

# üìå 3. Nettoyage et Pr√©-traitement des questions

# Charger les stopwords fran√ßais
stop_words = set(stopwords.words('french'))

# Fonction de nettoyage avec gestion d'erreur
def nettoyer_texte(texte):
    try:
        tokens = word_tokenize(texte.lower())  # Tokenisation avec NLTK
    except LookupError:
        tokens = texte.lower().split()  # Mode de secours en cas d'erreur

    tokens = [mot for mot in tokens if mot.isalnum() and mot not in stop_words]  # Suppression des stopwords et caract√®res sp√©ciaux
    return " ".join(tokens)

# Test du nettoyage
texte_test = "Quels sont les d√©bouch√©s apr√®s le Bac ?"
print(nettoyer_texte(texte_test))

# Appliquer le nettoyage sur l'ensemble du dataset
df["Question_clean"] = df["Question"].apply(nettoyer_texte)

# üéØ Objectif : Trouver une R√©ponse √† une Question avec TF-IDF
# Vectorisation TF-IDF
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df["Question_clean"])

def trouver_reponse(question):
    question_clean = nettoyer_texte(question)
    question_tfidf = vectorizer.transform([question_clean])
    similarites = cosine_similarity(question_tfidf, tfidf_matrix)
    index_meilleure = similarites.argmax()
    return df.iloc[index_meilleure]["R√©ponse"]

# Test du chatbot
question_utilisateur = "Comment devenir architect?"
print("Edu Pilot:", trouver_reponse(question_utilisateur))

question_utilisateur = "Qu'est ce que le m√©tier d'orthophoniste?"
print("Edu Pilot:", trouver_reponse(question_utilisateur))

# üíæ Sauvegarde du Mod√®le Chatbot
with open("./app/models/generated_models/vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)

print("‚úÖ Mod√®le vectorizer enregistr√© dans 'vectorizer.pkl'")

# 7. Initialisation du mod√®le Transformer pr√©-entra√Æn√©
model_name = "microsoft/DialoGPT-small"  # Mets le nom du mod√®le que tu veux utiliser (ex : Mistral ou DialoGPT-small)

# T√©l√©chargement et sauvegarde locale
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Sauvegarde en local
model.save_pretrained("./app/models/generated_models/chatbot_transformer_model")
tokenizer.save_pretrained("./app/models/generated_models/chatbot_transformer_model")

print("‚úÖ Mod√®le et tokenizer sauvegard√©s en local dans 'chatbot_transformer_model/'")